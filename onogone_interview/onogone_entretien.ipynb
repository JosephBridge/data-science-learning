{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise for 2nd interview at Onogone\n",
    "\n",
    "*Made by Anh-Thi DINH*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Goals\n",
    "\n",
    "- The goal is to build a binary classifier based on the attached corpus. Documents are classified as either belonging to the desired class (TRUE) or not (FALSE). \n",
    "- We would simply like you to have a look at the data and come up with one or several strategies to build such a classifier and maximize its accuracy.\n",
    "- This may include suggestions on how to pre-process, vectorize or resample the data or how to evaluate the classifier. \n",
    "- If time permits, code samples (in the language of your choice) in which you implement and evaluate your different strategies would be appreciated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Result (TL;DR;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm going to do in this notebook:\n",
    "\n",
    "1. Import the data with the encoding \"ANSI\" (I've found this by using Notepad in Windows, it's a trick) and take a look at the data set (**Section 4**).\n",
    "3. Data preprocessing : remove single charaters, remove stopwords, remove double spaces, remove special characters, make all letters to lower case (**Section 5**).\n",
    "4. Building a baseline model using Logistic Regression and evaluate the results. Before doing that, I vectorize the data into numerics (**Section 6.3**).\n",
    "5. Building some other classifiers using: Support Vector Machine (**Section 7.1**), Naive Bayes (**Section 7.2**), Random Forest (**Section 7.3**).\n",
    "6. Conclusion (**Section 8**) and some discussions for other methods to improve the results (**Section 9**).\n",
    "\n",
    "Below is the table of accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Table of results](./result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\ProgramData\\Anaconda3\\lib\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# text preprocessing\n",
    "import re\n",
    "import nltk # natural language toolkit\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "# for stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# split the data into train / test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# vectorize contents \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# different classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression # logistic regression\n",
    "from sklearn import svm # support vector machine\n",
    "from sklearn.naive_bayes import MultinomialNB # naive bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# evaluations\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "# from sklearn import metrics\n",
    "\n",
    "# cross validation\n",
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To Editor Re Penn Station Now Always Zach Gros...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother drone morning flew park wind carrie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This holiday advertising campaign United State...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Through dim memory South Bronx childhood blurr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LONDON For Queen Elizabeth II failed attend Ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  Classes\n",
       "0  To Editor Re Penn Station Now Always Zach Gros...        1\n",
       "1  My brother drone morning flew park wind carrie...        1\n",
       "2  This holiday advertising campaign United State...        1\n",
       "3  Through dim memory South Bronx childhood blurr...        1\n",
       "4  LONDON For Queen Elizabeth II failed attend Ch...        1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trick: using Notepad in Windows to findout the encoding of the csv file\n",
    "df = pd.read_csv(\"exerciceDS.csv\", encoding=\"ANSI\")\n",
    "\n",
    "# Change True/False to 1/0 for more easily looking\n",
    "df[\"Classes\"] = df[\"Classes\"].astype(int)\n",
    "\n",
    "# first look on the data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some information about data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5991 entries, 0 to 5990\n",
      "Data columns (total 2 columns):\n",
      "Content    5991 non-null object\n",
      "Classes    5991 non-null int32\n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of desired classes / not desired classes in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5635\n",
       "1     356\n",
       "Name: Classes, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Classes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Content'].values # returns a np array\n",
    "y = df['Classes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = []\n",
    "for i in range(0, len(X)):\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    content = re.sub(r'\\W', ' ', X[i])\n",
    "    \n",
    "    # remove all single characters\n",
    "    content = re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', content)\n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    content = re.sub(r'\\s+', ' ', content, flags=re.I)\n",
    "    \n",
    "    # make all letters to lower case\n",
    "    content = content.lower()\n",
    "        \n",
    "    # Lemmatization\n",
    "    content = content.split()\n",
    "    ps = PorterStemmer()\n",
    "    content = [ps.stem(word) for word in content if not word in set(stopwords)]\n",
    "    content = ' '.join(content)\n",
    "    \n",
    "    # add to contents\n",
    "    contents.append(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A baseline model\n",
    "\n",
    "We are going to build a simple model which is then used as a comparison with the more advanced models that you want to test. \n",
    "\n",
    "- In this baseline model, we don't make many things on the preprocessing text (removing stopwords, stemming,...)\n",
    "- We use BOW (bag-of-words) model to create vectors out of contents.\n",
    "- We use Logistic Regression (LoR) to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Verorizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vectorize `contents` into numbers using BOW and we limit the number of words in the vocabulary based on their frequency. It's because we don't want the words which appear few in contents affect our results. We don't want also the words that appear very-few or very-often between items in contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5991x2000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 714944 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize X using BOW\n",
    "vectorizer = CountVectorizer(max_features=2000, min_df=5, max_df=0.8, stop_words=stopwords)\n",
    "vectorizer.fit(contents)\n",
    "X = vectorizer.transform(contents)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that, `X` is a 5991x2000 matrix where 5991 is the number of training samples and 2000 is the size of the vocabulary created from `vectorizer` on `X`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Split data into train / test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 4493, X_test: 1498\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=273)\n",
    "print(\"X_train: {a}, X_test: {b}\".format(a=X_train.shape[0], b=X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Classifying using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoRclass = LogisticRegression()\n",
    "LoRclass.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LoRclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with different types of evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.999 (training), 0.983 (testing)\n",
      "Jaccard index: 0.983\n",
      "F1-score: 0.848\n",
      "Log loss: 0.576\n"
     ]
    }
   ],
   "source": [
    "# mean accuracy (higher is better)\n",
    "train_acc = LoRclass.score(X_train, y_train)\n",
    "test_acc = LoRclass.score(X_test, y_test)\n",
    "print(\"Mean accuracy: {:.3f} (training), {:.3f} (testing)\".format(train_acc, test_acc))\n",
    "\n",
    "# jaccard (higher is better)\n",
    "test_acc = jaccard_similarity_score(y_test, y_pred)\n",
    "print(\"Jaccard index: {:.3f}\".format(test_acc))\n",
    "\n",
    "# f1_score (higher is better)\n",
    "test_acc = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score: {:.3f}\".format(test_acc))\n",
    "\n",
    "# log loss (smaler is better)\n",
    "test_acc = log_loss(y_test, y_pred)\n",
    "print(\"Log loss: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our problem, *F1-score* should be used than the others because we need a precision in our prediction (0 or 1). The *Log loss* is usually used for predicted values which are probability values between 0 and 1.\n",
    "\n",
    "The training accuracy is very high (almost 1), it may lead to an overfitting problem. We try using a Cross-Validation (K-fold for example) to get a better evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.984 (+/- 0.016)\n",
      "F1-score accuracy: 0.861 (+/- 0.117)\n"
     ]
    }
   ],
   "source": [
    "# Make cross validated predictions\n",
    "scores = cross_val_score(LoRclass, X, y, cv=7, scoring='accuracy')\n",
    "print(\"Accuracy score: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(LoRclass, X, y, cv=7, scoring='f1') # binary\n",
    "print(\"F1-score accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Other models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Classifying using Support Vector Machine algorithm (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVMclass = svm.SVC()\n",
    "SVMclass.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVMclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with different types of evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy (SVM): 0.987 (training), 0.977 (testing)\n",
      "Jaccard index: 0.977\n",
      "F1-score: 0.761\n"
     ]
    }
   ],
   "source": [
    "# mean accuracy (higher is better)\n",
    "train_acc = SVMclass.score(X_train, y_train)\n",
    "test_acc = SVMclass.score(X_test, y_test)\n",
    "print(\"Mean accuracy (SVM): {:.3f} (training), {:.3f} (testing)\".format(train_acc, test_acc))\n",
    "\n",
    "# jaccard (higher is better)\n",
    "test_acc = jaccard_similarity_score(y_test, y_pred)\n",
    "print(\"Jaccard index: {:.3f}\".format(test_acc))\n",
    "\n",
    "# f1_score (higher is better)\n",
    "test_acc = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with a cross validation to check the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.979 (+/- 0.011)\n",
      "F1-score accuracy: 0.789 (+/- 0.121)\n"
     ]
    }
   ],
   "source": [
    "# Make cross validated predictions\n",
    "scores = cross_val_score(SVMclass, X, y, cv=7, scoring='accuracy')\n",
    "print(\"Accuracy score: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(SVMclass, X, y, cv=7, scoring='f1')\n",
    "print(\"F1-score accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, SVM **take more time to execute** but **it doesn't give any better result** than Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Classifying using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBclass = MultinomialNB()\n",
    "NBclass.fit(X_train, y_train)\n",
    "y_pred = NBclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy (NBclass): 0.935 (training), 0.929 (testing)\n",
      "Jaccard index: 0.929\n",
      "F1-score: 0.604\n"
     ]
    }
   ],
   "source": [
    "# mean accuracy (higher is better)\n",
    "train_acc = NBclass.score(X_train, y_train)\n",
    "test_acc = NBclass.score(X_test, y_test)\n",
    "print(\"Mean accuracy (NBclass): {:.3f} (training), {:.3f} (testing)\".format(train_acc, test_acc))\n",
    "\n",
    "# jaccard (higher is better)\n",
    "test_acc = jaccard_similarity_score(y_test, y_pred)\n",
    "print(\"Jaccard index: {:.3f}\".format(test_acc))\n",
    "\n",
    "# f1_score (higher is better)\n",
    "test_acc = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.886 (+/- 0.182)\n",
      "F1-score accuracy: 0.563 (+/- 0.342)\n"
     ]
    }
   ],
   "source": [
    "# Make cross validated predictions\n",
    "scores = cross_val_score(NBclass, X, y, cv=7, scoring='accuracy')\n",
    "print(\"Accuracy score: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(NBclass, X, y, cv=7, scoring='f1')\n",
    "print(\"F1-score accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes take **less time to execute** but **the result is not so good!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFclass = RandomForestClassifier(n_estimators=1000, random_state=0) # 1000 trees\n",
    "RFclass.fit(X_train, y_train)\n",
    "y_pred = RFclass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy (RFclass): 1.000 (training), 0.979 (testing)\n",
      "Jaccard index: 0.979\n",
      "F1-score: 0.784\n"
     ]
    }
   ],
   "source": [
    "# mean accuracy (higher is better)\n",
    "train_acc = RFclass.score(X_train, y_train)\n",
    "test_acc = RFclass.score(X_test, y_test)\n",
    "print(\"Mean accuracy (RFclass): {:.3f} (training), {:.3f} (testing)\".format(train_acc, test_acc))\n",
    "\n",
    "# jaccard (higher is better)\n",
    "test_acc = jaccard_similarity_score(y_test, y_pred)\n",
    "print(\"Jaccard index: {:.3f}\".format(test_acc))\n",
    "\n",
    "# f1_score (higher is better)\n",
    "test_acc = f1_score(y_test, y_pred, average='binary')\n",
    "print(\"F1-score: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.980 (+/- 0.012)\n",
      "F1-score accuracy: 0.801 (+/- 0.113)\n"
     ]
    }
   ],
   "source": [
    "# Make cross validated predictions\n",
    "scores = cross_val_score(RFclass, X, y, cv=7, scoring='accuracy')\n",
    "print(\"Accuracy score: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "scores = cross_val_score(RFclass, X, y, cv=7, scoring='f1')\n",
    "print(\"F1-score accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we take a very large number of trees for the RF, it takes too much time to execute but the result is really good in comparison with other algorithms (not with Logistic Regression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the Logistic Regression is the best one among above methods. The runner-up is the Random Forest but it takes a lot of time to execute the code (we can take fewer trees to make it faster). Both of them lead easily to the overfitting problem if we fix a train/test set at the beginning (both give 1 in the training accuracy). That's why we need a cross-validation step to evaluate our methods and the results are not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other algorithms we can use to classify our data. Besides that, we can also modify the parameters in our algorithms to make a better results (if possible). Below are some options:\n",
    "\n",
    "1. Change the `CountVectorizer`'s parameters, such as: increasing the number of features (`max_features`), number of trusted words (`min_df`, `max_df`) \n",
    "2. Instead of using `CountVectorizer`, we can try with `TfidfVectorizer`.\n",
    "3. Feature scaling (not so helpful for the Random Forest)\n",
    "4. Try Word Embedding with the help of **Word2Vec** or something like that.\n",
    "5. Try to use Neural Networks with the help of **Keras**.\n",
    "\n",
    "Because I don't have too much time to take into account all of above things, I'll leave them for future researches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
